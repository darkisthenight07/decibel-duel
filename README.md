# Conditional GAN for Audio Synthesis ğŸ¶

This repository contains the code for **Task 2: A deep learning-based generative model for audio synthesis**. 
 The project implements a Wasserstein Generative Adversarial Network with Gradient Penalty (WGAN-GP) using PyTorch and torchaudio to generate realistic, category-specific audio clips. The model is trained on log-mel spectrograms and can produce novel audio samples for any of the predefined categories it was trained on.

This implementation is designed to be run in a Google Colab environment, leveraging its free GPU resources for efficient training.

## ğŸš€ Features

* **Conditional Generation**: The WGAN generates audio conditioned on a specific class label, allowing for targeted audio synthesis.
* **WGAN-GP Architecture**: Uses Wasserstein loss with gradient penalty for stable training and improved convergence compared to vanilla GANs.
* **Spectrogram-Based**: The model operates in the frequency domain by generating log-mel spectrograms, a robust representation for audio data.
* **Sample Generation**: At the end of every 20 epochs, the model saves generated audio samples (`.wav`) and plots of their corresponding spectrograms.
* **Two-Stage Workflow**: Separate preprocessing and training notebooks for efficient resource utilization.
* **Optimized Training Pipeline**: Includes mixed precision training (AMP), increased batch sizes, and pre-computed spectrograms for faster iteration as compared to provided sample code.
* **Checkpoint System**: Automatic saving and loading of model checkpoints to resume training seamlessly.
* **Google Colab Ready**: Includes necessary setup for mounting Google Drive to access datasets.

### ğŸ—ï¸ Key Optimizations
* Precomputed Mel spectograms for faster processing.
* Increased Batch Size for stable training.
* Shorter Spectrograms for faster training.
* Enable the cuDNN auto-tuner to find the most efficient algorithms for our specific hardware and model configuration.
* Mixed Precision for faster training.
* Ignoring user warnings for cleaner output.

---

## ğŸ—ï¸ Model Architecture

The project implements a WGAN-GP architecture with two main components:

### 1. Generator (The Audio Synthesizer ğŸ¨)
The WGAN_Generator creates audio spectrograms from random noise and a label embedding:
```
Input: Noise (100D) + Label Embedding (16D)
  â†“
Linear Projection â†’ Reshape
  â†“
ConvTranspose2d (512 â†’ 256) + BatchNorm + ReLU
  â†“
ConvTranspose2d (256 â†’ 128) + BatchNorm + ReLU
  â†“
ConvTranspose2d (128 â†’ 64) + BatchNorm + ReLU
  â†“
ConvTranspose2d (64 â†’ 1) + ReLU
  â†“
Output: Log-Mel Spectrogram (1Ã—128Ã—256)
```

### 2. Critic (The Detective ğŸ•µï¸)
The WGAN_Critic evaluates the quality of spectrograms:
```
Input: Spectrogram (1Ã—128Ã—256) + Label Embedding (16D)
  â†“
Concatenate â†’ (2Ã—128Ã—256)
  â†“
Conv2d (2 â†’ 32) + LeakyReLU
  â†“
Conv2d (32 â†’ 64) + LeakyReLU
  â†“
Conv2d (64 â†’ 128) + LeakyReLU
  â†“
Conv2d (128 â†’ 256) + LeakyReLU
  â†“
Conv2d (256 â†’ 1)
  â†“
Output: Wasserstein Distance (scalar)
```

### WGAN-GP Training Details

* Gradient Penalty: Enforces Lipschitz constraint for stable training (weight: 10.0)
* Critic Updates: 5 critic updates per generator update
* Optimizer: Adam with learning rate 1e-4, betas (0.5, 0.9)
* Mixed Precision: Automatic mixed precision (AMP) for faster training on modern GPUs

---

### Prerequisites
* A Google Account (for Google Colab and Google Drive).
* Your audio dataset organized by category.

## ğŸ“‚ Dataset Structure
```
drive/MyDrive/decibel_duel/
â”œâ”€â”€ train/
â”‚   â”œâ”€â”€ train/                    # Raw audio files
â”‚   â”‚   â”œâ”€â”€ dog_bark/
â”‚   â”‚   â”‚   â”œâ”€â”€ audio_001.wav
â”‚   â”‚   â”‚   â”œâ”€â”€ audio_002.wav
â”‚   â”‚   â”‚   â””â”€â”€ ...
â”‚   â”‚   â”œâ”€â”€ drilling/
â”‚   â”‚   â”‚   â”œâ”€â”€ sound_A.wav
â”‚   â”‚   â”‚   â””â”€â”€ ...
â”‚   â”‚   â”œâ”€â”€ engine_idling/
â”‚   â”‚   â”œâ”€â”€ siren/
â”‚   â”‚   â””â”€â”€ street_music/
â”‚   â”‚
â”‚   â””â”€â”€ precompute/              # Pre-computed spectrograms (generated)
â”‚       â”œâ”€â”€ dog_bark/
â”‚       â”œâ”€â”€ drilling/
â”‚       â””â”€â”€ ...
â”‚
â”œâ”€â”€ checkpoints/                 # Model checkpoints (auto-created)
â”‚   â””â”€â”€ wgan_audio.pth.tar
â”‚
â””â”€â”€ samples/                     # Generated samples (auto-created)
    â”œâ”€â”€ epoch_020.png
    â””â”€â”€ gan_generated_audio/
```

## ğŸ“š References

* [Base Sample Code](https://github.com/ankush-10010/Decibal-Duel)
* [Improved Training of WGANs](https://arxiv.org/abs/1704.00028)
* [PyTorch Documentation](https://pytorch.org/docs/)
* [Torchaudio Documentation](https://pytorch.org/audio/)

## ğŸ“œ License

This project is licensed under the MIT License. See the `LICENSE` file for details.
